{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6e26f036ab1dd2568d3979abf5890674c5c132ffd7da08cb3e6229af913b809c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b5507429d626>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KDEF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m \u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneutral_paths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mneutral_faces\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfaces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_KDEF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b5507429d626>\u001b[0m in \u001b[0;36m_load_KDEF\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mneutral_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneutral_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_angle\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'S'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0mface_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m                 \u001b[0mcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;31m# there are two file names in the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "def preprocess_input(x, v2=True):\n",
    "    x = x.astype('float32')\n",
    "    x = x / 255.0\n",
    "    if v2:\n",
    "        x = x - 0.5\n",
    "        x = x * 2.0\n",
    "    return x\n",
    "\n",
    "\n",
    "class DataManager(object):\n",
    "    \"\"\"Class for loading fer2013 emotion classification dataset or\n",
    "        imdb gender classification dataset.\"\"\"\n",
    "    def __init__(self, dataset_name='imdb',\n",
    "                 dataset_path=None, image_size=(48, 48)):\n",
    "\n",
    "        self.dataset_name = dataset_name\n",
    "        self.dataset_path = dataset_path\n",
    "        self.image_size = image_size\n",
    "        if self.dataset_path is not None:\n",
    "            self.dataset_path = dataset_path\n",
    "        elif self.dataset_name == 'imdb':\n",
    "            self.dataset_path = '../datasets/imdb_crop/imdb.mat'\n",
    "        elif self.dataset_name == 'fer2013':\n",
    "            self.dataset_path = '../datasets/fer2013/fer2013.csv'\n",
    "        elif self.dataset_name == 'KDEF':\n",
    "            self.dataset_path = './kdef/KDEF/'\n",
    "        else:\n",
    "            raise Exception(\n",
    "                    'Incorrect dataset name, please input imdb or fer2013')\n",
    "\n",
    "    def get_data(self):\n",
    "        if self.dataset_name == 'imdb':\n",
    "            ground_truth_data = self._load_imdb()\n",
    "        elif self.dataset_name == 'fer2013':\n",
    "            ground_truth_data = self._load_fer2013()\n",
    "        elif self.dataset_name == 'KDEF':\n",
    "            ground_truth_data = self._load_KDEF()\n",
    "        return ground_truth_data\n",
    "\n",
    "    def _load_imdb(self):\n",
    "        face_score_treshold = 3\n",
    "        dataset = loadmat(self.dataset_path)\n",
    "        image_names_array = dataset['imdb']['full_path'][0, 0][0]\n",
    "        gender_classes = dataset['imdb']['gender'][0, 0][0]\n",
    "        face_score = dataset['imdb']['face_score'][0, 0][0]\n",
    "        second_face_score = dataset['imdb']['second_face_score'][0, 0][0]\n",
    "        face_score_mask = face_score > face_score_treshold\n",
    "        second_face_score_mask = np.isnan(second_face_score)\n",
    "        unknown_gender_mask = np.logical_not(np.isnan(gender_classes))\n",
    "        mask = np.logical_and(face_score_mask, second_face_score_mask)\n",
    "        mask = np.logical_and(mask, unknown_gender_mask)\n",
    "        image_names_array = image_names_array[mask]\n",
    "        gender_classes = gender_classes[mask].tolist()\n",
    "        image_names = []\n",
    "        for image_name_arg in range(image_names_array.shape[0]):\n",
    "            image_name = image_names_array[image_name_arg][0]\n",
    "            image_names.append(image_name)\n",
    "        return dict(zip(image_names, gender_classes))\n",
    "\n",
    "    def _load_fer2013(self):\n",
    "        data = pd.read_csv(self.dataset_path)\n",
    "        pixels = data['pixels'].tolist()\n",
    "        width, height = 48, 48\n",
    "        faces = []\n",
    "        for pixel_sequence in pixels:\n",
    "            face = [int(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(width, height)\n",
    "            face = cv2.resize(face.astype('uint8'), self.image_size)\n",
    "            faces.append(face.astype('float32'))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "        emotions = pd.get_dummies(data['emotion']).as_matrix()\n",
    "        return faces, emotions\n",
    "\n",
    "    def _load_KDEF(self):\n",
    "        class_to_arg = get_class_to_arg(self.dataset_name)\n",
    "        num_classes = len(class_to_arg)\n",
    "\n",
    "        file_paths = []\n",
    "        for folder, subfolders, filenames in os.walk(self.dataset_path):\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith('.jpg'):\n",
    "                    \n",
    "                    file_paths.append(os.path.join(folder, filename))\n",
    "\n",
    "        num_faces = len(file_paths)\n",
    "        neutral_count = 0\n",
    "        cc=0\n",
    "        y_size, x_size = self.image_size\n",
    "        faces = np.zeros(shape=(num_faces, y_size, x_size))\n",
    "        face_data = np.zeros(shape=(980, y_size, x_size))\n",
    "        neutral_faces = np.zeros(shape=(int(num_faces/5), y_size, x_size))\n",
    "        neutral_paths = []\n",
    "\n",
    "        face_data = []\n",
    "        emotions = np.zeros(shape=(num_faces, num_classes))\n",
    "        for file_arg, file_path in enumerate(file_paths):\n",
    "            image_array = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "            image_array = cv2.resize(image_array, (y_size, x_size))\n",
    "            faces[file_arg] = image_array\n",
    "            file_basename = os.path.basename(file_path)\n",
    "            file_emotion = file_basename[4:6]\n",
    "            file_angle = file_basename[6]\n",
    "            if(file_emotion == \"NE\"):\n",
    "                neutral_faces[neutral_count] = image_array\n",
    "                neutral_paths.append(file_path)\n",
    "                neutral_count = neutral_count + 1\n",
    "            if(file_angle=='S'):\n",
    "                face_data[cc] = image_array\n",
    "                cc = cc + 1\n",
    "            # there are two file names in the dataset\n",
    "            # that don't match the given classes\n",
    "            try:\n",
    "                emotion_arg = class_to_arg[file_emotion]\n",
    "            except:\n",
    "                continue\n",
    "            emotions[file_arg, emotion_arg] = 1\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "        return file_paths,neutral_paths,neutral_faces,faces, emotions\n",
    "\n",
    "\n",
    "def get_labels(dataset_name):\n",
    "    if dataset_name == 'fer2013':\n",
    "        return {0: 'AN', 1: 'DI', 2: 'AF', 3: 'HA',\n",
    "                4: 'SA', 5: 'SU', 6: 'NE'}\n",
    "    elif dataset_name == 'imdb':\n",
    "        return {0: 'woman', 1: 'man'}\n",
    "    elif dataset_name == 'KDEF':\n",
    "        return {0: 'AN', 1: 'DI', 2: 'AF', 3: 'HA', 4: 'SA', 5: 'SU', 6: 'NE'}\n",
    "    else:\n",
    "        raise Exception('Invalid dataset name')\n",
    "\n",
    "\n",
    "def get_class_to_arg(dataset_name='fer2013'):\n",
    "    if dataset_name == 'fer2013':\n",
    "        return {'AN': 0, 'DI': 1, 'AF': 2, 'HA': 3, 'SA': 4,\n",
    "                'SU': 5, 'NE': 6}\n",
    "    elif dataset_name == 'imdb':\n",
    "        return {'woman': 0, 'man': 1}\n",
    "    elif dataset_name == 'KDEF':\n",
    "        return {'AN': 0, 'DI': 1, 'AF': 2, 'HA': 3, 'SA': 4, 'SU': 5, 'NE': 6}\n",
    "    else:\n",
    "        raise Exception('Invalid dataset name')\n",
    "\n",
    "\n",
    "def split_imdb_data(ground_truth_data, validation_split=.2, do_shuffle=False):\n",
    "    ground_truth_keys = sorted(ground_truth_data.keys())\n",
    "    if do_shuffle is not False:\n",
    "        shuffle(ground_truth_keys)\n",
    "    training_split = 1 - validation_split\n",
    "    num_train = int(training_split * len(ground_truth_keys))\n",
    "    train_keys = ground_truth_keys[:num_train]\n",
    "    validation_keys = ground_truth_keys[num_train:]\n",
    "    return train_keys, validation_keys\n",
    "\n",
    "\n",
    "def split_data(x, y, validation_split=.2):\n",
    "    num_samples = len(x)\n",
    "    num_train_samples = int((1 - validation_split)*num_samples)\n",
    "    train_x = x[:num_train_samples]\n",
    "    train_y = y[:num_train_samples]\n",
    "    val_x = x[num_train_samples:]\n",
    "    val_y = y[num_train_samples:]\n",
    "    train_data = (train_x, train_y)\n",
    "    val_data = (val_x, val_y)\n",
    "    return train_data, val_data\n",
    "\n",
    "a = DataManager('KDEF')\n",
    "file_paths,neutral_paths,neutral_faces,faces, emotions = a._load_KDEF()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4898, 48, 48, 1)\n(4898, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(faces.shape)\n",
    "print(emotions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os,cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 20, 10\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras.models import model_from_json\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import *\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.datasets import make_classification\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['angry','disgust','afraid','happy','sadness','surprise','neutral']\n",
    "\n",
    "def getLabel(id):\n",
    "    return ['angry','disgust','afraid','happy','sadness','surprise','neutral'][id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3918, 48, 48, 1)\n"
     ]
    }
   ],
   "source": [
    "x,y = shuffle(faces,emotions, random_state=2)\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt \n",
    "import numpy as np \n",
    "import scipy.misc \n",
    "from IPython.display import display \n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def create_model(input_shape=(48,48,1)):\n",
    "    # first input model\n",
    "    visible = Input(shape=input_shape, name='input')\n",
    "    num_classes = 7\n",
    "    #the 1-st block\n",
    "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
    "    conv1_1 = BatchNormalization()(conv1_1)\n",
    "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
    "    conv1_2 = BatchNormalization()(conv1_2)\n",
    "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
    "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)\n",
    "\n",
    "    #the 2-nd block\n",
    "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
    "    conv2_1 = BatchNormalization()(conv2_1)\n",
    "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
    "    conv2_2 = BatchNormalization()(conv2_2)\n",
    "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
    "    conv2_2 = BatchNormalization()(conv2_3)\n",
    "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
    "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)\n",
    "\n",
    "    #the 3-rd block\n",
    "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
    "    conv3_1 = BatchNormalization()(conv3_1)\n",
    "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
    "    conv3_2 = BatchNormalization()(conv3_2)\n",
    "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
    "    conv3_3 = BatchNormalization()(conv3_3)\n",
    "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
    "    conv3_4 = BatchNormalization()(conv3_4)\n",
    "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
    "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)\n",
    "\n",
    "    #the 4-th block\n",
    "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
    "    conv4_1 = BatchNormalization()(conv4_1)\n",
    "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
    "    conv4_2 = BatchNormalization()(conv4_2)\n",
    "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
    "    conv4_3 = BatchNormalization()(conv4_3)\n",
    "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
    "    conv4_4 = BatchNormalization()(conv4_4)\n",
    "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
    "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
    "\n",
    "    #the 5-th block\n",
    "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
    "    conv5_1 = BatchNormalization()(conv5_1)\n",
    "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
    "    conv5_2 = BatchNormalization()(conv5_2)\n",
    "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
    "    conv5_3 = BatchNormalization()(conv5_3)\n",
    "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
    "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)\n",
    "\n",
    "    #Flatten and output\n",
    "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
    "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)\n",
    "\n",
    "    # create model \n",
    "    model = Model(inputs =visible, outputs = ouput)\n",
    "    # summary layers\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='RMSprop')\n",
    "         index                         path  angle  emotion\n",
    "0     BF07   kdef/KDEF/BF07/BF07SAS.JPG      4        4\n",
    "1     BF07  kdef/KDEF/BF07/BF07SAFL.JPG      0        4\n",
    "2     BF07  kdef/KDEF/BF07/BF07NEHR.JPG      3        6\n",
    "3     BF07  kdef/KDEF/BF07/BF07SAHL.JPG      2        4\n",
    "4     BF07  kdef/KDEF/BF07/BF07DIHR.JPG      3        1\n",
    "...    ...                          ...    ...      ...\n",
    "4893  AM10  kdef/KDEF/AM10/AM10HAHR.JPG      3        3\n",
    "4894  AM10  kdef/KDEF/AM10/AM10SAHR.JPG      3        4\n",
    "4895  AM10  kdef/KDEF/AM10/AM10SAFL.JPG      0        4\n",
    "4896  AM10  kdef/KDEF/AM10/AM10NEFR.JPG      1        6\n",
    "4897  AM10   kdef/KDEF/AM10/AM10HAS.JPG      4        3\n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_model_lite():\n",
    "    input_shape=(48,48,1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6, (5, 5), input_shape=input_shape, padding='same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(16, (5, 5), padding='same', activation = 'relu'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation = 'relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(7, activation = 'softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer='adam')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 48, 48, 6)         156       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 24, 24, 6)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 24, 24, 16)        2416      \n_________________________________________________________________\nactivation (Activation)      (None, 24, 24, 16)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 12, 12, 16)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 10, 10, 64)        9280      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 1600)              0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               204928    \n_________________________________________________________________\ndropout (Dropout)            (None, 128)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 7)                 903       \n=================================================================\nTotal params: 217,683\nTrainable params: 217,683\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= create_model_lite()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=25, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, \n",
    "    zoom_range=0.2,horizontal_flip=True, \n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ch 19/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.8891 - accuracy: 0.1970 - val_loss: 1.8256 - val_accuracy: 0.2633\n",
      "Epoch 20/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.8793 - accuracy: 0.2055 - val_loss: 1.8715 - val_accuracy: 0.2214\n",
      "Epoch 21/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.8737 - accuracy: 0.1998 - val_loss: 1.8119 - val_accuracy: 0.2490\n",
      "Epoch 22/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.8566 - accuracy: 0.2182 - val_loss: 1.7820 - val_accuracy: 0.2551\n",
      "Epoch 23/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.8597 - accuracy: 0.2200 - val_loss: 1.7769 - val_accuracy: 0.2337\n",
      "Epoch 24/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.8454 - accuracy: 0.2340 - val_loss: 1.7840 - val_accuracy: 0.2551\n",
      "Epoch 25/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.8287 - accuracy: 0.2295 - val_loss: 1.7372 - val_accuracy: 0.3041\n",
      "Epoch 26/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.8265 - accuracy: 0.2437 - val_loss: 1.7552 - val_accuracy: 0.2745\n",
      "Epoch 27/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.8149 - accuracy: 0.2496 - val_loss: 1.7139 - val_accuracy: 0.2949\n",
      "Epoch 28/200\n",
      "123/123 [==============================] - 5s 39ms/step - loss: 1.8116 - accuracy: 0.2534 - val_loss: 1.6985 - val_accuracy: 0.3245\n",
      "Epoch 29/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.7942 - accuracy: 0.2652 - val_loss: 1.6896 - val_accuracy: 0.3286\n",
      "Epoch 30/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.7752 - accuracy: 0.2652 - val_loss: 1.6337 - val_accuracy: 0.3296\n",
      "Epoch 31/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.7457 - accuracy: 0.2869 - val_loss: 1.5816 - val_accuracy: 0.3714\n",
      "Epoch 32/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.7216 - accuracy: 0.2915 - val_loss: 1.5533 - val_accuracy: 0.3806\n",
      "Epoch 33/200\n",
      "123/123 [==============================] - 3s 28ms/step - loss: 1.7029 - accuracy: 0.3063 - val_loss: 1.5181 - val_accuracy: 0.4194\n",
      "Epoch 34/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.6912 - accuracy: 0.3139 - val_loss: 1.5175 - val_accuracy: 0.3929\n",
      "Epoch 35/200\n",
      "123/123 [==============================] - 4s 30ms/step - loss: 1.6721 - accuracy: 0.3216 - val_loss: 1.4909 - val_accuracy: 0.4041\n",
      "Epoch 36/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.6517 - accuracy: 0.3407 - val_loss: 1.4960 - val_accuracy: 0.3990\n",
      "Epoch 37/200\n",
      "123/123 [==============================] - 5s 38ms/step - loss: 1.6483 - accuracy: 0.3374 - val_loss: 1.5181 - val_accuracy: 0.3939\n",
      "Epoch 38/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.6553 - accuracy: 0.3331 - val_loss: 1.5165 - val_accuracy: 0.4031\n",
      "Epoch 39/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.6219 - accuracy: 0.3550 - val_loss: 1.4327 - val_accuracy: 0.4255\n",
      "Epoch 40/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.6219 - accuracy: 0.3402 - val_loss: 1.4276 - val_accuracy: 0.4357\n",
      "Epoch 41/200\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 1.5907 - accuracy: 0.3660 - val_loss: 1.4522 - val_accuracy: 0.4143\n",
      "Epoch 42/200\n",
      "123/123 [==============================] - 5s 38ms/step - loss: 1.5777 - accuracy: 0.3698 - val_loss: 1.4076 - val_accuracy: 0.4571\n",
      "Epoch 43/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.5946 - accuracy: 0.3640 - val_loss: 1.4408 - val_accuracy: 0.4276\n",
      "Epoch 44/200\n",
      "123/123 [==============================] - 5s 38ms/step - loss: 1.5720 - accuracy: 0.3765 - val_loss: 1.3975 - val_accuracy: 0.4510\n",
      "Epoch 45/200\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 1.5893 - accuracy: 0.3573 - val_loss: 1.3868 - val_accuracy: 0.4469\n",
      "Epoch 46/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.5535 - accuracy: 0.3752 - val_loss: 1.3463 - val_accuracy: 0.4622\n",
      "Epoch 47/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.5588 - accuracy: 0.3806 - val_loss: 1.3532 - val_accuracy: 0.4796\n",
      "Epoch 48/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.5510 - accuracy: 0.3851 - val_loss: 1.3430 - val_accuracy: 0.5010\n",
      "Epoch 49/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.5416 - accuracy: 0.3869 - val_loss: 1.4094 - val_accuracy: 0.4429\n",
      "Epoch 50/200\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 1.5227 - accuracy: 0.3989 - val_loss: 1.3633 - val_accuracy: 0.4541\n",
      "Epoch 51/200\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 1.5425 - accuracy: 0.3954 - val_loss: 1.3510 - val_accuracy: 0.4745\n",
      "Epoch 52/200\n",
      "123/123 [==============================] - 4s 30ms/step - loss: 1.5016 - accuracy: 0.4173 - val_loss: 1.3482 - val_accuracy: 0.4724\n",
      "Epoch 53/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.5246 - accuracy: 0.4028 - val_loss: 1.3356 - val_accuracy: 0.4622\n",
      "Epoch 54/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.5176 - accuracy: 0.4015 - val_loss: 1.3134 - val_accuracy: 0.4908\n",
      "Epoch 55/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.5029 - accuracy: 0.4058 - val_loss: 1.3030 - val_accuracy: 0.4969\n",
      "Epoch 56/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.4962 - accuracy: 0.4099 - val_loss: 1.3306 - val_accuracy: 0.4776\n",
      "Epoch 57/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.4923 - accuracy: 0.4099 - val_loss: 1.2950 - val_accuracy: 0.5041\n",
      "Epoch 58/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.4947 - accuracy: 0.4096 - val_loss: 1.3795 - val_accuracy: 0.4704\n",
      "Epoch 59/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.4795 - accuracy: 0.4201 - val_loss: 1.3479 - val_accuracy: 0.4724\n",
      "Epoch 60/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.4917 - accuracy: 0.4051 - val_loss: 1.3981 - val_accuracy: 0.4500\n",
      "Epoch 61/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.4578 - accuracy: 0.4247 - val_loss: 1.3417 - val_accuracy: 0.4673\n",
      "Epoch 62/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.4820 - accuracy: 0.4209 - val_loss: 1.3349 - val_accuracy: 0.4857\n",
      "Epoch 63/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.4664 - accuracy: 0.4209 - val_loss: 1.2575 - val_accuracy: 0.5061\n",
      "Epoch 64/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.4656 - accuracy: 0.4109 - val_loss: 1.2798 - val_accuracy: 0.4816\n",
      "Epoch 65/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.4602 - accuracy: 0.4339 - val_loss: 1.2534 - val_accuracy: 0.5122\n",
      "Epoch 66/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.4644 - accuracy: 0.4206 - val_loss: 1.2679 - val_accuracy: 0.5071\n",
      "Epoch 67/200\n",
      "123/123 [==============================] - 5s 40ms/step - loss: 1.4416 - accuracy: 0.4273 - val_loss: 1.3108 - val_accuracy: 0.4765\n",
      "Epoch 68/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.4383 - accuracy: 0.4308 - val_loss: 1.3159 - val_accuracy: 0.4959\n",
      "Epoch 69/200\n",
      "123/123 [==============================] - 5s 40ms/step - loss: 1.4440 - accuracy: 0.4382 - val_loss: 1.2826 - val_accuracy: 0.4878\n",
      "Epoch 70/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.4366 - accuracy: 0.4298 - val_loss: 1.3804 - val_accuracy: 0.4510\n",
      "Epoch 71/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.4237 - accuracy: 0.4377 - val_loss: 1.2881 - val_accuracy: 0.4878\n",
      "Epoch 72/200\n",
      "123/123 [==============================] - 4s 29ms/step - loss: 1.4156 - accuracy: 0.4416 - val_loss: 1.2710 - val_accuracy: 0.5010\n",
      "Epoch 73/200\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 1.4182 - accuracy: 0.4398 - val_loss: 1.2989 - val_accuracy: 0.4847\n",
      "Epoch 74/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.4276 - accuracy: 0.4372 - val_loss: 1.2668 - val_accuracy: 0.5071\n",
      "Epoch 75/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.4420 - accuracy: 0.4324 - val_loss: 1.2897 - val_accuracy: 0.4969\n",
      "Epoch 76/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.4099 - accuracy: 0.4477 - val_loss: 1.2308 - val_accuracy: 0.5184\n",
      "Epoch 77/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.4038 - accuracy: 0.4553 - val_loss: 1.2916 - val_accuracy: 0.5041\n",
      "Epoch 78/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.3965 - accuracy: 0.4548 - val_loss: 1.3187 - val_accuracy: 0.4878\n",
      "Epoch 79/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.4203 - accuracy: 0.4446 - val_loss: 1.2612 - val_accuracy: 0.5061\n",
      "Epoch 80/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.4073 - accuracy: 0.4571 - val_loss: 1.2413 - val_accuracy: 0.5102\n",
      "Epoch 81/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.3846 - accuracy: 0.4546 - val_loss: 1.2231 - val_accuracy: 0.5286\n",
      "Epoch 82/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.3881 - accuracy: 0.4569 - val_loss: 1.2875 - val_accuracy: 0.4847\n",
      "Epoch 83/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.3962 - accuracy: 0.4650 - val_loss: 1.2062 - val_accuracy: 0.5224\n",
      "Epoch 84/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.3834 - accuracy: 0.4592 - val_loss: 1.2337 - val_accuracy: 0.5296\n",
      "Epoch 85/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.3691 - accuracy: 0.4666 - val_loss: 1.2090 - val_accuracy: 0.5245\n",
      "Epoch 86/200\n",
      "123/123 [==============================] - 4s 30ms/step - loss: 1.3831 - accuracy: 0.4625 - val_loss: 1.2316 - val_accuracy: 0.5245\n",
      "Epoch 87/200\n",
      "123/123 [==============================] - 5s 38ms/step - loss: 1.3669 - accuracy: 0.4622 - val_loss: 1.4459 - val_accuracy: 0.4398\n",
      "Epoch 88/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.3666 - accuracy: 0.4701 - val_loss: 1.5008 - val_accuracy: 0.4051\n",
      "Epoch 89/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.3931 - accuracy: 0.4543 - val_loss: 1.2018 - val_accuracy: 0.5337\n",
      "Epoch 90/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.3622 - accuracy: 0.4706 - val_loss: 1.2110 - val_accuracy: 0.5173\n",
      "Epoch 91/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.3699 - accuracy: 0.4645 - val_loss: 1.2396 - val_accuracy: 0.5306\n",
      "Epoch 92/200\n",
      "123/123 [==============================] - 4s 33ms/step - loss: 1.3780 - accuracy: 0.4699 - val_loss: 1.3312 - val_accuracy: 0.4714\n",
      "Epoch 93/200\n",
      "123/123 [==============================] - 4s 36ms/step - loss: 1.3817 - accuracy: 0.4612 - val_loss: 1.2033 - val_accuracy: 0.5357\n",
      "Epoch 94/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.3671 - accuracy: 0.4681 - val_loss: 1.2108 - val_accuracy: 0.5255\n",
      "Epoch 95/200\n",
      "123/123 [==============================] - 4s 31ms/step - loss: 1.3874 - accuracy: 0.4684 - val_loss: 1.2561 - val_accuracy: 0.4949\n",
      "Epoch 96/200\n",
      "123/123 [==============================] - 5s 37ms/step - loss: 1.3469 - accuracy: 0.4775 - val_loss: 1.2261 - val_accuracy: 0.5112\n",
      "Epoch 97/200\n",
      "123/123 [==============================] - 4s 34ms/step - loss: 1.3488 - accuracy: 0.4709 - val_loss: 1.2167 - val_accuracy: 0.5245\n",
      "Epoch 98/200\n",
      "123/123 [==============================] - 4s 35ms/step - loss: 1.3643 - accuracy: 0.4615 - val_loss: 1.2128 - val_accuracy: 0.5265\n",
      "Epoch 99/200\n",
      "123/123 [==============================] - 4s 32ms/step - loss: 1.3374 - accuracy: 0.4778 - val_loss: 1.1801 - val_accuracy: 0.5316\n",
      "Epoch 100/200\n",
      "123/123 [==============================] - 4s 29ms/step - loss: 1.3441 - accuracy: 0.4676 - val_loss: 1.1994 - val_accuracy: 0.5337\n",
      "Epoch 101/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.3449 - accuracy: 0.4760 - val_loss: 1.2243 - val_accuracy: 0.5224\n",
      "Epoch 102/200\n",
      "123/123 [==============================] - 3s 22ms/step - loss: 1.3315 - accuracy: 0.4796 - val_loss: 1.2137 - val_accuracy: 0.5204\n",
      "Epoch 103/200\n",
      "123/123 [==============================] - 3s 22ms/step - loss: 1.3614 - accuracy: 0.4699 - val_loss: 1.2102 - val_accuracy: 0.5296\n",
      "Epoch 104/200\n",
      "123/123 [==============================] - 3s 22ms/step - loss: 1.3415 - accuracy: 0.4826 - val_loss: 1.2387 - val_accuracy: 0.5327\n",
      "Epoch 105/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.3511 - accuracy: 0.4681 - val_loss: 1.2374 - val_accuracy: 0.5143\n",
      "Epoch 106/200\n",
      "123/123 [==============================] - 3s 22ms/step - loss: 1.3435 - accuracy: 0.4814 - val_loss: 1.2882 - val_accuracy: 0.5102\n",
      "Epoch 107/200\n",
      "123/123 [==============================] - 3s 22ms/step - loss: 1.3601 - accuracy: 0.4747 - val_loss: 1.2243 - val_accuracy: 0.5173\n",
      "Epoch 108/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.3423 - accuracy: 0.4712 - val_loss: 1.1677 - val_accuracy: 0.5327\n",
      "Epoch 109/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.3395 - accuracy: 0.4735 - val_loss: 1.2378 - val_accuracy: 0.5276\n",
      "Epoch 110/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.3501 - accuracy: 0.4760 - val_loss: 1.3014 - val_accuracy: 0.4908\n",
      "Epoch 1/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 3.2122 - accuracy: 0.1363 - val_loss: 1.9435 - val_accuracy: 0.1461\n",
      "Epoch 2/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9461 - accuracy: 0.1447 - val_loss: 1.9451 - val_accuracy: 0.1502\n",
      "Epoch 3/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9468 - accuracy: 0.1373 - val_loss: 1.9476 - val_accuracy: 0.1430\n",
      "Epoch 4/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9463 - accuracy: 0.1299 - val_loss: 1.9460 - val_accuracy: 0.1471\n",
      "Epoch 5/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9462 - accuracy: 0.1363 - val_loss: 1.9455 - val_accuracy: 0.1471\n",
      "Epoch 6/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9465 - accuracy: 0.1429 - val_loss: 1.9448 - val_accuracy: 0.1614\n",
      "Epoch 7/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9468 - accuracy: 0.1332 - val_loss: 1.9453 - val_accuracy: 0.1450\n",
      "Epoch 8/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9464 - accuracy: 0.1365 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 9/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9453 - accuracy: 0.1357 - val_loss: 1.9459 - val_accuracy: 0.1440\n",
      "Epoch 10/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9448 - accuracy: 0.1273 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 11/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9453 - accuracy: 0.1442 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 12/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9445 - accuracy: 0.1365 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 13/200\n",
      "123/123 [==============================] - 3s 22ms/step - loss: 1.9445 - accuracy: 0.1452 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 14/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9449 - accuracy: 0.1309 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 15/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9453 - accuracy: 0.1411 - val_loss: 1.9473 - val_accuracy: 0.1430\n",
      "Epoch 16/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9456 - accuracy: 0.1312 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 17/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9455 - accuracy: 0.1347 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 18/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9452 - accuracy: 0.1375 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 19/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9445 - accuracy: 0.1332 - val_loss: 1.9458 - val_accuracy: 0.1420\n",
      "Epoch 20/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9445 - accuracy: 0.1434 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 21/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9454 - accuracy: 0.1419 - val_loss: 1.9459 - val_accuracy: 0.1450\n",
      "Epoch 22/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9447 - accuracy: 0.1281 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 23/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9452 - accuracy: 0.1286 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 24/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9454 - accuracy: 0.1337 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 25/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9446 - accuracy: 0.1291 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 26/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9449 - accuracy: 0.1360 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 27/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9444 - accuracy: 0.1335 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 28/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9438 - accuracy: 0.1332 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 29/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9445 - accuracy: 0.1383 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 30/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9440 - accuracy: 0.1373 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 31/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9446 - accuracy: 0.1444 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 32/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9447 - accuracy: 0.1327 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 33/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9444 - accuracy: 0.1357 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 34/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9443 - accuracy: 0.1447 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 35/200\n",
      "123/123 [==============================] - 3s 23ms/step - loss: 1.9446 - accuracy: 0.1368 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 36/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9445 - accuracy: 0.1380 - val_loss: 1.9459 - val_accuracy: 0.1420\n",
      "Epoch 1/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 2.4711 - accuracy: 0.1355 - val_loss: 1.9458 - val_accuracy: 0.1440\n",
      "Epoch 2/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9460 - accuracy: 0.1340 - val_loss: 1.9460 - val_accuracy: 0.1430\n",
      "Epoch 3/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9462 - accuracy: 0.1350 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 4/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9463 - accuracy: 0.1322 - val_loss: 1.9460 - val_accuracy: 0.1440\n",
      "Epoch 5/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9461 - accuracy: 0.1268 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 6/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9462 - accuracy: 0.1322 - val_loss: 1.9459 - val_accuracy: 0.1440\n",
      "Epoch 7/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9461 - accuracy: 0.1355 - val_loss: 1.9461 - val_accuracy: 0.1420\n",
      "Epoch 8/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9461 - accuracy: 0.1386 - val_loss: 1.9459 - val_accuracy: 0.1430\n",
      "Epoch 9/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9472 - accuracy: 0.1373 - val_loss: 1.9462 - val_accuracy: 0.1512\n",
      "Epoch 10/200\n",
      "123/123 [==============================] - 3s 24ms/step - loss: 1.9467 - accuracy: 0.1375 - val_loss: 1.9458 - val_accuracy: 0.1420\n"
     ]
    }
   ],
   "source": [
    "\n",
    "EPOCHS = 200\n",
    "result=[]\n",
    "scores_loss = []\n",
    "scores_acc = []\n",
    "k_no = 0\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_Train_ = faces[train_index]\n",
    "    Y_Train = emotions[train_index]\n",
    "    X_Test_ = faces[test_index]\n",
    "    Y_Test = emotions[test_index]\n",
    "\n",
    "    file_path = \"./\"+str(k_no)+\".hdf5\"\n",
    "    checkpoint = ModelCheckpoint(file_path, monitor='loss', verbose=0, save_best_only=True, mode='min')\n",
    "    early = EarlyStopping(monitor=\"loss\", mode=\"min\", patience=8)\n",
    "\n",
    "    callbacks_list = [checkpoint, early]\n",
    "\n",
    "    model = create_model_lite()\n",
    "    hist = model.fit_generator(aug.flow(X_Train_, Y_Train), epochs=EPOCHS,validation_data=(X_Test_, Y_Test), callbacks=callbacks_list, verbose=1)\n",
    "    # model.fit(X_Train, Y_Train, batch_size=batch_size, epochs=epochs, validation_data=(X_Test, Y_Test), verbose=1)\n",
    "    model.load_weights(file_path)\n",
    "    result.append(model.predict(X_Test_))\n",
    "    score = model.evaluate(X_Test_,Y_Test, verbose=0)\n",
    "    scores_loss.append(score[0])\n",
    "    scores_acc.append(score[1])\n",
    "    k_no+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.5469387755102041\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn import metrics\n",
    "\n",
    "model = load_model('2'+'.hdf5')\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(metrics.accuracy_score(y_test.argmax(axis=1),y_pred.argmax(axis=1)))"
   ]
  }
 ]
}